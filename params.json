{
  "name": "Principal Components Analysis (PCA) in R",
  "tagline": "",
  "body": "### Introduction to Principal Components Analysis\r\nPrincipal Components Analysis (PCA) is a multivariate technique used to reduce a large data set into fewer \"components\". Without getting too technical, it examples all possible correlations (_specifically linear combinations_) of each variable, and organizes them into a smaller set of components which account for the greatest proportion of the data. Resulting components are orthogonal to each other (e.g., the second component is orthogonal to the first, the third component is orthogonal to the second) in order to account for the most variance as possible. A useful summary of PCA can be found here: [Principal Components Analysis Overview](https://www.utdallas.edu/~herve/abdi-awPCA2010.pdf)\r\n\r\nThe data used for this example is a Kaggle dataset about normal or abnormal spinal positioning, with twelve measured spinal variables. The dataset can be found here: [Spinal Data](https://github.com/mjtat/Principal-Components-Analysis-in-R/blob/master/Dataset_spine.csv)\r\n\r\nThe full script can be found here: [pca.R](https://github.com/mjtat/Principal-Components-Analysis-in-R/blob/master/pca.R)\r\n\r\n\r\n\r\n***\r\n\r\n\r\n### First, read in the data, and re-code the data.\r\n    # Read in the data\r\n    spine_dat <- read.csv(\"Dataset_spine.csv\", header = TRUE, stringsAsFactors = FALSE)\r\n\r\n    #Re-label the class column\r\n    spine_dat$Class_att[spine_dat$Class_att == \"Abnormal\"] <- 1\r\n    spine_dat$Class_att[spine_dat$Class_att == \"Normal\"] <- 2\r\n\r\n### Conduct the PCA, look at the component loadings (eigenvectors) for the first five variables\r\n    # Conduct the pca using the prcomp() function. Center will center all variables, and scaling \r\n    # will standardize all the variables.\r\n\r\n    spine_PCA <- prcomp(spine_dat, center = TRUE, scale. = TRUE)\r\n\r\n    # Retrieve the first 5 prinicipal component loadings.\r\n    head(spine_PCA$rotation, 5)\r\n    \r\n    spine_PCA_summary <- summary(spine_PCA)\r\n\r\n### Manually generate variances and standard deviations (these values are also provided by the summary function above).\r\n\r\n    # Generate the PCA standard deviations\r\n    spinePCA_SD<-spine_PCA$sdev\r\n\r\n    # Generate the PCA variances\r\n    spinePCA_var <- round(spinePCA_SD^2, digits = 3)\r\n\r\n    # Generate the proportion of variance for each component\r\n    propvar_spinePCA <- spinePCA_var / sum(spinePCA_var)\r\n\r\n### Generate a scree plot and bar plot of the components (x-axis) and variance accounted for (y-axis)\r\n\r\n    # Produce a screeplot and a barplot of the amount of variance each component contributes.\r\n    plot(spine_PCA_summary$importance[2, 1:12], xlab = \"Principal Component\", ylab = \"Proportion of Variance Explained\", type = \"h\")\r\n\r\n    barplot(spine_PCA_summary$importance[2, 1:12], xlab = \"Principal Component\", ylab = \"Proportion of Variance Explained\")\r\n\r\n### Resulting plots\r\n\r\n![](https://github.com/mjtat/Principal-Components-Analysis-in-R/blob/master/PCA_Screeplot.png?raw=true)\r\n\r\n\r\n![](https://github.com/mjtat/Principal-Components-Analysis-in-R/blob/master/PCA_barplot.png?raw=true)\r\n\r\n**One rule to determine how many of the components to keep for later analyses is to search for the \"elbow\" of the plots Another qualitative way is to take the number of components where the variance is < 1. However, these methods are generally qualitative, and Horn's Parallel Analysis is now preferred as a method to determine how many components to keep. Horn's analysis calculates the 95% percentile eigenvalue value, and uses that as a cutoff.**\r\n\r\n    # Conduct Horn's Parallel Analysis\r\n    library(\"paran\")\r\n    horn<-paran(spine_dat, iterations = 5000, centile = 0, quietly = FALSE, \r\n          status = TRUE, all = TRUE, cfa = FALSE, seed = 0)\r\n\r\n    -------------------------------------------------- \r\n    Component   Adjusted    Unadjusted    Estimated \r\n                Eigenvalue  Eigenvalue    Bias \r\n    -------------------------------------------------- \r\n    1           2.947658    3.279216      0.331558\r\n    2           1.001448    1.245541      0.244092\r\n    3           0.966187    1.143004      0.176816\r\n    4           0.937743    1.055545      0.117802\r\n    5           0.959352    1.023933      0.064580\r\n    6           0.952924    0.967660      0.014735\r\n    7           0.926671    0.893034     -0.03363\r\n    8           0.965511    0.884368     -0.08114\r\n    9           0.856166    0.726670     -0.12949\r\n    10          0.646394    0.467974     -0.17841\r\n    11          0.544201    0.313050     -0.23115\r\n    12          0.295739   0.000000     -0.29573\r\n    -------------------------------------------------- \r\n\r\n    Adjusted eigenvalues > 1 indicate dimensions to retain.\r\n    (2 components retained)\r\n\r\n**Horn's analysis suggests only keeping any components over the adjusted eigenvalue of 1. It's not clear necessarily what these two components mean. One possibility is that these components generally summarize whether the spinal position is abnormal or normal. Additional models may choose to compare a full PCA with 12 components and a reduced PCA to see which model may fit future data better.**",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}